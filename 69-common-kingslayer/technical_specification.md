# Distributed tracing with OpenTelemetry and Jaeger (Common Kingslayer)
**Epic Type:** Implementation Epic

Epic planning and implementation follow the
[Epic Planning and Marathon SOP](https://docs.ghga-dev.de/main/sops/sop001_epic_planning.html).

## Scope
### Outline:

Based on some previous exploration work, this epic aims to implement 1) OpenTelemetry instrumentation across file services in the file service monorepo and 2) in the remaining backend services along the download path, i.e. at least work-package and auth services and 3) necessary OpenTelemetry functionality inside of hexkit and/or ghga-service-commons.
The spans generated by the implementation should cover multiple services and as much of the request lifecycle as possible.
In addition, a viable setup of Jaeger and its components needs to be devised and implemented.

### Included/Required:

While OpenTelemetry supports tracing, metrics and logging, this epic will focus on enabling collection of distributed tracing data and neglect the other two aspects.

#### File Services:
File services can export tracing data using manual or autoinstrumentation or a combination of both.
Autoinstrumentation works by installing specific libraries that monkeypatch existing functionality to inject information that can be propagated across service boundaries.
In this document autoinstrumentation always means instrumentation provided by third-party libraries.
While these are quite quite useful, they should be vetted for what data is attached to the traces and manual instrumentation should be used instead, if sensitive information is included.
If autoinstrumentation can be used in all/most cases, additional implementation work can be kept to a minimum.

The following list of (auto)instrumentation libraries have been used during exploration and seem the most promising:

```python
opentelemetry-api
opentelemetry-sdk
opentelemetry-exporter-otlp
opentelemetry-distro
opentelemetry-instrumentation
opentelemetry-instrumentation-logging
opentelemetry-instrumentation-aiokafka
opentelemetry-instrumentation-botocore
opentelemetry-instrumentation-fastapi
opentelemetry-instrumentation-httpx
opentelemetry-instrumentation-pymongo
opentelemetry-instrumentation-requests
````

While there is an asyncio autoinstrumentation library, it did not provide any further value to what's already covered by the other libraries.
Additionally, the logging autoinstrumentation can be ignored as we are focusing on tracing.
If any of these third-party libraries are not fit for our use case, they need to be replaced with manual instrumentation, so that we are able to obtain tracing information for the following operations:

- Sending and receiving kafka events
- Database access for MongoDB
- Boto operations
- Incoming HTTP requests
- Outgoing HTTP requests

Additional manual instrumentation can be provided by creating a global `TracerProvider` and opening spans within the code using either contextmanagers or decorators.
By default these will attach to an existing parent span generating a hierarchy of subspans across services.
Additionally, to traverse service boundaries, HTTP and Kafka headers are populated with the necessary information, which is extracted at the receving end.
Some additional code dealing with this process will be required, if the corresponding autoinstrumentation library is not used which can be implemented in hexkit for Kafka, MongoDB and boto or as middleware in ghga-service-commons for HTTP operations.

As a basic example, assume a parent span already exists for a FastAPI application, then a custom subspan could be opened with the following code

```
# Initialize the TracerProvider in the service inject.py

from opentelemetry import trace
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.resources import SERVICE_NAME, Resource
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

...

resource = Resource(attributes={SERVICE_NAME: service_name})
trace_provider = TracerProvider(resource=resource)
# Endpoint can be overwritten by config, but needs to be provided
processor = BatchSpanProcessor(OTLPSpanExporter(endpoint="http://localhost"))
trace_provider.add_span_processor(processor)
trace.set_tracer_provider(trace_provider) 


# Create new span for a FastAPI endpoint (decorator)
@tracer.start_as_current_span("Descriptive span name")
async def my_dummy_endpoint():
    ...

# Create new span for a FastAPI endpoint (context manager)
async def my_other_dummy_endpoint():
    with tracer.start_as_current_span("Descriptive span name"):
        ...
```

This will produce a very lightweight span in both cases, which can be enriched with additional (meta)data, if desired.
For this purpose, the context manager is more flexible, as additional span data can be populated dynamically within the function body, while the decorator can only be enriched with statically available data.

#### Correlation ID
It is not fully clear if we can inject and thus reuse our existing correlation ID within the OpenTelemetry framework.
With the current understanding of how context propagation across services works, this might be as easy as renaming the corresponding headers for both HTTP requests and Kafka events to something that OpenTelemetry understands.
The open question here is if autoinstrumentation libraries would interfere with this and overwrite the value or if, conversely, we might need to intercept autoinstrumentation headers and modify them.

#### Hexkit/Service Commons:
Hexkit needs some changes introducing logic around event subscribers to correctly propagate tracing context across service boundaries as the autoinstrumentation for Kafka does not open a new child span, ending the propagation at the event subscriber.

Depending on if some autoinstrumentation is replaced or enhanced by manual instrumentation, there might be a need to touch some middleware, which would be done in ghga-service-commons.

#### Jaeger Setup:

Jaeger consists of three different components: Jaeger Collector, Jager Query and Jaeger UI. 
An all-in-one deployment bundling all three components is also available, which is normally used for development, but could be a viable option for our deployment for now.
Jaeger Collector additionally needs a backing database for persistent storage of the traces it receives via OpenTelemetry, with multiple options available to choose from.

As OpenTelemetry backends should be easily interchangeable, it is left to the DevOps team to evaluate whether we want to stick with Jaeger or if another solution might integrate better with our existing tooling.

### Not Included:

- Dealing with metrics and logs through OpenTelemetry.
- Exploration of other backends than Jaeger.

## Additional Implementation Details:

Potentially there are some trade offs to be made both for the Jaeger deployment and when choosing autoinstrumentation vs manual instrumentation.
Depending on the answers to some of the open questions, there might be some additional implementation work included, but overall no major code changes should be needed in either case.

Implementation work will use the `otel_test` branches of hexkit and the file services backend monorepo as starting point.

## Human Resource/Time Estimation:

Number of sprints required: 1

Number of developers required: 1
